% !TeX root = ../geometry_main.tex
%==========================================================
%=========================================================
\chapter{Differential geometry leftovers}
%=========================================================
%=========================================================


In this long chapter, we collect various random topics in differential geometry that I feel like writing down.


%-----------------------------------------------------------------------
%========================================================
\section{Derivatives on tensors}
%=========================================================
%-----------------------------------------------------------------------

There are infinitely many notions of derivatives on tensors.
In general, a (anti)-derivative of degree $(h,k)$ on tensors is a map from a suitable subset $\mathcal{D}$ of the tensor bundle 
\begin{equation}
    \delta: T^{\bullet}_{\bullet} (M)\subseteq \mathcal{D} \to T^{\bullet + h}_{\bullet + k} (M)
\end{equation}
that is linear and satisfies a Leibniz rule, up to a sign.
That is 
\begin{equation}
    \delta (S \otimes T) = (\delta S) \otimes T + (\pm)^{pq} S \otimes (\delta T),
\end{equation}
We call it \emph{anti}derivative if it changes sign when acting on the two factors of a tensor product.
For example, the exterior derivative $d$ is an antiderivative of degree $(0,1)$ on  differential forms, and the inner derivative $i_X$ along a vector field $X$ is an antiderivative of degree $(0,-1)$ on differential forms. 


\noindent
\textbf{Uniqueness theorem for derivatives on tensors.}\\
An (anti)-derivative $\delta$ on tensors--i.e. a linear map and obeying Leibniz rule up to a possible minus sign-- is completely determined by its action on functions and vector fields, or equivalently on functions and 1-forms.
\medskip


%========================================================
\subsection{Lie derivative}
%=========================================================

\begin{mytheorem}[Lie derivative as commutator of vector fields]
The Lie derivative $\mathcal{L}_X$ along a vector field $X$ is the unique derivative of degree $(0,0)$ on tensors that reduces to the usual directional derivative when acting on functions and to the usual Lie bracket $\mathcal{L}_X Y = [X,Y]$ when acting on vector fields.
It is then extended to all tensors using linearity and the Leibniz rule
\begin{equation}
    \mathcal{L}_X (S \otimes T) = (\mathcal{L}_X S) \otimes T + S \otimes (\mathcal{L}_X T).
\end{equation}
\end{mytheorem}


\begin{mytheorem}[Lie derivative as flow derivative]
The Lie derivative is equivalently defined as the infinitesimal generator of the flow induced by a vector field \(X\).
Namely, given a tensor field \(T\in T^{\bullet}_{\bullet} (M)\), we define the Lie derivative along \(X\) as
\begin{equation}
    \mathcal{L}_X T := \lim_{\epsilon \to 0} \frac{\phi_{X,\epsilon}^* (T) - T}.{ \epsilon},
\end{equation}
where \(\phi_{X,\epsilon}: M \to M\) is the flow generated by the vector field \(X\) for parameter distance \(\epsilon\) and \(\phi_{X,\epsilon}^*\) is the pullback map induced by \(\phi_{X,\epsilon}\) on tensors.
\end{mytheorem}


\begin{mytheorem}[Cartan formula \& yet another way to define the Lie derivative]
A fundamental result linking the Lie derivative $\mathcal{L}_X$, the exterior derivative $d$ and the inner derivative $i_X$.
Namely, for any differential form $\omega$, we have
\begin{equation}
    \mathcal{L}_X \omega = i_X d \omega + d (i_X \omega).
\end{equation}
The right-hand side is defined only for differential forms, but the left-hand side makes sense for any tensor.
Since differential forms include functions (0-forms) and differentials (1-forms), we can use this formula to \emph{define} the Lie derivative and then extend it to all tensors using linearity and the Leibniz rule.
\end{mytheorem}

\begin{mytheorem}[The Lie derivative is ignorant of the curvature \& the metric]
As evident from any of its definitions, the Lie derivative does not depend on any notion of connection or metric on the manifold.
It only depends on the smooth-- i.e. differential-- structure of the manifold, being defined in terms of commutators, or flows or exterior and inner derivatives.
It thus cannot give any information on the curvature of the manifold beyond the constrained already encoded in the smooth structure itself.
\end{mytheorem}


%========================================================
\subsection{Parallel transport, connection \& covariant derivative}
%=========================================================


Parallel transport and covariant derivative are two faces of the same coin.
Namely, covariant derivative can be defined as the infinitesimal generator of parallel transport along curves.

\begin{mytheorem}[Parallel transport]
A parallel transport along a curve $\gamma: [0,1] \to M$ is a \emph{bijective linear} map 
\begin{equation}
    \tau_{\gamma}: T_{\gamma(0)} M \to T_{\gamma(1)} M
\end{equation}
such that for any two tensor fields
\begin{equation}\label{}
    \tau_{\gamma} (S \otimes T) = \tau_{\gamma} (S) \otimes \tau_{\gamma} (T).
\end{equation}
In order to obtain a well-defined notion of parallel transport, we must consistently define such a map for any curve $\gamma$ connecting any two points of the manifold.
Just like for dervatives on tensors, the parallel transport is completely determined by its action on functions and vector fields, or equivalently on functions and 1-forms.
\end{mytheorem}


\begin{mytheorem}[Connection]
A connection is a \emph{derivative} of degree $(0,1)$ on tensors, i.e. obeys linearity and Leibniz rule,
\begin{equation}
    \nabla: T^{\bullet}_{\bullet} (M) \to T^{\bullet}_{\bullet + 1} (M),
\end{equation}
that reduces to the usual directional derivative when acting on function.
It is completely determined by its action on functions and vector fields, or equivalently on functions and 1-forms.
In particular, one defines the Christoffel symbols $\Gamma^{\rho}_{\mu \nu}$ with respect to a coordinate basis as
\begin{equation}
    \nabla_{\partial_\mu} \partial_\nu = \Gamma^{\rho}_{\mu \nu} \partial_\rho.
\end{equation}
By the Leibniz rule, the general action on a $(h,k)$-tensor field $T$ reads
\begin{equation}\label{eq:connection_on_tensor}
    \nabla_{\partial_\mu} T^{\nu_1 \dots \nu_h}_{ \rho_1 \dots \rho_k} 
    = \partial_\mu\left( T^{\nu_1 \dots \nu_h}_{ \rho_1 \dots \rho_k} \right)
    + \sum_{i=1}^h \Gamma^{\nu_i}_{\mu \sigma} \,T^{\nu_1 \dots \sigma \dots \nu_h}_{ \rho_1 \dots \rho_k} 
    - \sum_{j=1}^k \Gamma^{\sigma}_{\mu \rho_j}\, T^{\nu_1 \dots \nu_h}_{\rho_1 \dots \sigma \dots \rho_k}.
\end{equation}
Note that the value of $\nabla_X T$ at a point $p\in M$ depends only on the values of $T$ along any curve whose tangent at $p$ is $X_p$.
\end{mytheorem}

\begin{mytheorem}[Covariant derivative \& connection as infinitesimal generator of parallel transport]
Given a curve $\gamma: [0,1] \to M$ and a connection $\nabla$, the parallel transport $\tau_{\gamma}$ along $\gamma$ generated by $\nabla$ is defined as the unique map such that for any tensor field $T\in T_{\gamma(0)} M$ the curve $t \mapsto T(t) := \tau_{\gamma|_{[0,t]}} (T)$ satisfies the parallel transport equation
\begin{equation}
    0 = \nabla_{\dot{\gamma}(t)} T(t) 
\end{equation}
As usual, it is sufficient to define it on functions and vector fields, or equivalently on functions and 1-forms, and then extend it to all tensors using linearity and the Leibniz rule.
The parallel transport map is well-defined thanks to standard theorems on existence and uniqueness of solutions of ODEs.

If we are given a tensor field $S(t)$ along the curve $\gamma$, we can define the covariant derivative along $\gamma$ as
\begin{equation}
    \frac{D}{dt}S(t) := \lim_{\epsilon \to 0} \frac{\tau_{\gamma|_{[t+\epsilon,t]}}^{-1} (S(t+\epsilon)) - S(t)}.{\epsilon} 
\end{equation}
That is we use parallel transport induced by $\nabla$ to compare tensors at different points along the curve.
This is indeed way $\nabla$ is called \emph{connection}: it gives a way to connect and compare `generalied tangent planes' i.e. tensors at different points.
As expected, we obtain back the covariant derivative gives back the original expression in terms of the connection
\begin{equation}
    \frac{D}{dt}S(t) := \lim_{\epsilon \to 0} \frac{\tau_{\gamma|_{[t+\epsilon,t]}}^{-1} (S(t+\epsilon)) - S(t)}
    \equiv \nabla_{\dot{\gamma}(t)} S(t),
\end{equation}
where we use that \eqref{eq:connection_on_tensor} depends only on the values of $S$ along the curve whose tangent at $p$ is $\dot{\gamma}(t)$.
\end{mytheorem}





%-----------------------------------------------------------------------
%========================================================
\section{Differential forms \& integration} \todotag{To be written}
%=========================================================
%-----------------------------------------------------------------------


\begin{mytheorem}[Indices bookkeeping for differential forms]
The canonical basis for $\Lambda^k(M)$ is written as $dx^{i_1} \wedge \cdots \wedge dx^{i_k}$ with $i_1 < i_2 < \cdots < i_k$.
We will insetad use indices $\sigma_1, \dots, \sigma_k \subseteq \{1, \dots, n\}$ to denote unordered indices.
A $k$-form $\omega \in \Lambda^k (M)$ can be written equivalently as
\begin{align}\label{eq:indices_bookkeeping_differential_forms}
\begin{aligned}
    \omega &= \sum_{i_1 < \cdots < i_k} \omega_{i_1 \dots i_k} dx^{i_1} \wedge \cdots \wedge dx^{i_k}
    \\
    &= \frac{1}{k!} \sum_{\sigma_1, \dots, \sigma_k} \omega_{\sigma_1 \dots \sigma_k} dx^{\sigma_1} \wedge \cdots \wedge dx^{\sigma_k}
    \\
    &= \sum_{\sigma_1, \dots, \sigma_k} \omega_{\sigma_1 \dots \sigma_k}\, dx^{\sigma_1} \otimes \cdots \otimes dx^{\sigma_k},
\end{aligned}
\end{align}
In the first expression we do not sum over repeated indices, which are ordered $i_1 \dots i_k$.
In the second expression we instead sum over the \emph{unordered} indices $\sigma_1, \dots, \sigma_k$, we define $\omega_{\sigma_1 \dots \sigma_k}$ to be totally antisymmetric, and divide by $k!$ to avoid overcounting.
In the third expression we explicitate the wedge product in terms of antisymmetrized tensor product: because $\omega_{\sigma_1 \dots \sigma_k}$ is already totally antisymmetric, and we are still summing over the $\sigma$ indices, the double counting cancel $1/k!$ factor.
\end{mytheorem}



%========================================================
\subsection{Derivatives on differential forms} \todotag{To be written}
%=========================================================

For differential forms (anti)-derivatives of degree $k\in \mathbb{Z}$ obeys the Leibniz rule in the form
\begin{equation}
    \delta: \Lambda^\bullet (M) \to \Lambda^{\bullet+k} (M), \qquad \delta (\alpha \wedge \beta) = (\delta \alpha) \wedge \beta + (\pm1)^{|\alpha||\beta|} \alpha \wedge (\delta \beta).
\end{equation}

\begin{mytheorem}[Lie derivative on differential forms]
The Lie derivative is a well-behaved derivative of degree $(0,0)$ on differential forms, defined as the restriction of the usual Lie derivative on tensors.
From the Leibniz rule for tensors and the linearity of the antisymmetrization map, it immediately follows that the Lie derivative also obeys the Leibniz rule wrt the wedge product
\begin{equation}
    \mathcal{L}_X(\alpha \wedge \beta) = (\mathcal{L}_X \alpha) \wedge \beta + \alpha \wedge (\mathcal{L}_X \beta).
\end{equation}
\end{mytheorem}


\begin{mytheorem}[Inner derivative]
The inner derivative is a \emph{anti}derivative of degree $(0,-1)$ on differential forms, defined as the contraction along a vector field $X$
\begin{equation}
    i_X: \Lambda^k (M) \to \Lambda^{k-1} (M)\quad  \mid\quad  i_X \omega := \omega (X, \cdot, \cdots, \cdot) 
\end{equation}
In a basis of $\Lambda^{k-1}(M)$ i.e. for \emph{ordered} indices $i_1< \dots <i_{k-1}$, but summing over \emph{any} value $\sigma\in \{1\dots n\}$, we have
\begin{equation}\label{eq:interior_derivative_basis_expr}
   (i_X \omega) = X^{\sigma}\, \omega_{\sigma i_1 \dots i_{k-1}} \, dx^{i_1} \wedge \cdots \wedge dx^{i_{k-1}}
\end{equation} 
where again $\omega_{\sigma_0 \dots \sigma_k}$ is totally antisymmetric.
Indeed, using the convention \eqref{eq:indices_bookkeeping_differential_forms}, we have
\begin{align}
\begin{aligned}
    i_X(\omega) &= \sum_{\sigma_0 \dots \sigma_{k-1}} \omega_{\sigma_0 \dots \sigma_{k-1}}\, dx^{\sigma_0}\otimes \cdots \otimes dx^{\sigma_{k-1}}\, (X, \cdots)
    \\
    &= \sum_{\sigma_0 \dots \sigma_{k-1}} X^{\sigma_0} \, \omega_{\sigma_0 \sigma_1 \dots \sigma_{k-1}}dx^{\sigma_1}\otimes \cdots \otimes dx^{\sigma_{k-1}}
    \\
    &= \sum_{\sigma_0 \in\{1\dots n\},\,\,i_1 < \cdots < i_{k-1}} X^{\sigma_0} \, \omega_{\sigma_0 i_1 \dots i_{k-1}}\,\,dx^{i_1}\wedge\cdots \wedge dx^{i_{k-1}}.
\end{aligned}
\end{align}
\end{mytheorem}


\begin{mytheorem}[Exterior derivative]
The exterior derivative is an \emph{anti}derivative of degree $(0,1)$ on differential forms, defined as the unique map
\begin{equation}
    d: \Lambda^k (M) \to \Lambda^{k+1} (M)
\end{equation}
that reduces to the usual differential when acting on functions and satisfies $d^2 = 0$.
Under this conditions, one proves the usual formula in a coordinate basis
\begin{equation}\label{eq:exterior_deriv_basis_expr}
    d \Big(\omega_{i_1 \dots i_k} dx^{i_1} \wedge \cdots \wedge dx^{i_k}\Big) = \partial_\mu \omega_{i_1 \dots i_k} \, dx^{\mu} \wedge dx^{i_1} \wedge \cdots \wedge dx^{i_k}.
\end{equation}
\end{mytheorem}



%========================================================
\subsection{Integration} \todotag{To be written}
%=========================================================

\begin{mytheorem}[Integration of differential forms]
Given an oriented submanifold $S^{(k)} \subseteq M^{(n)}$ of dimension $k$, we can integrate $k$-forms $\omega \in \Lambda^k (M)$ over $S$.
Namely, given a parametrization $\phi: U \subseteq \mathbb{R}^k \to S \subseteq M$, we define
\begin{equation}
    \int_S \omega := \int_U \phi^* (\omega).
\end{equation}
Note that $\phi^* (\omega) \in \Lambda^k (U)$ is a $k$-form on $\mathbb{R}^k$, which can be written as $f(x) dx^1 \wedge \cdots \wedge dx^k$ for some function $f: U \to \mathbb{R}$, and then integrated as usual.
The orientation of $S$ is necessary to have a well-defined integral, since changing the orientation changes the sign of the integral, but orientability of $M$ is not necessary.
\end{mytheorem}

\begin{mytheorem}[Stokes theorem]
This is simply the fundamental theorem of calculus for differential forms.
Namely, for any \emph{oriented} manifold $M^{(n)}$ with boundary $\partial M$ and any differential form $\omega \in \Lambda^{n-1} (M)$, we have
\begin{equation}
    \int_M d\omega = \int_{\partial M} \omega.
\end{equation}
In particular, Stokes theorem formalizes a fundamental relation between the purely algebraic property $d^2 = 0$ and the purely geometric property $\partial ^2 M =0$ i.e. the `boundary of a boundary is empty'.
\end{mytheorem}


%-----------------------------------------------------------------------------
\subsubsection{Rediscovering familiar operations}
%-----------------------------------------------------------------------------

\begin{mytheorem}[Divergence \& Gauss theorem.]
Given a volume form $\Omega$ and a vector field $X$ on a manifold $M^{(n)}$, define the \textbf{divergence} as the $n$-form
\begin{equation}
    \mathrm{div}_\Omega (X) := \mathcal{L}_X \Omega = d (i_X \Omega) + i_X \graycancel{d\Omega} = d (i_X \Omega).
\end{equation}
Note that this definition is independent of the notion of metric once we are given a volume form $\Omega$.
We can compute the divergence using the expressions \eqref{eq:interior_derivative_basis_expr}-\eqref{eq:exterior_deriv_basis_expr} for $i_x$ and $d$, but it is much easier to use the Leibniz rule for $\mathcal{L}$.
Writing $\Omega = a(x) dx^1 \wedge \cdots \wedge dx^n$ for some nowhere-vanishing function $a$
\begin{align}
    \mathrm{div}_\Omega (X) 
    &= \big(\mathcal{L}_X a\big)\,\,dx^1 \wedge \cdots \wedge dx^n + a(x) \sum_{\mu=1}^n dx^1 \wedge \cdots \wedge \mathcal{L}_X(dx^\mu) \wedge \cdots \wedge dx^n
    \\&= X(a) \, dx^1 \wedge \cdots \wedge dx^n + a(x) \sum_{\mu=1}^n dx^1 \wedge \cdots \wedge dX^{\mu} \wedge \cdots \wedge dx^n
    \\&= \left( X(a) + a(x) \sum_{\mu=1}^n \partial_{\mu} X^{\mu} \right) dx^1 \wedge \cdots \wedge dx^n 
    \\&= \left( \frac{1}{a(x)} \partial_{\mu} \big(a(x) X^{\mu}\big) \right) \, \Omega.
\end{align}
Note that we recover the usual formula for divergence in $\mathbb{R}^n$ when $a(x) = 1$.
\smallskip

More generally, when $\Omega = \sqrt{|g|} dx^1 \wedge \cdots \wedge dx^n$ is the \textbf{metric volume form}, we have
\begin{equation}
    \mathrm{div}_g (X) = \left( \frac{1}{\sqrt{|g|}} \partial_{\mu} \Big(\sqrt{|g|} X^{\mu}\Big) \right) \Omega_g = \left( \nabla_{\mu} X^{\mu} \right) \Omega_g.
\end{equation}
The last equality follows from the definition $\nabla_{\mu}X^\mu= \partial_\mu X^\mu + \Gamma_{\mu \nu}^\mu X^\nu$ and the well-known identity $\Gamma_{\mu \nu}^\mu = \frac{1}{\sqrt{|g|}} \partial_\nu \sqrt{|g|}$ proven in \eqref{eq:metric_christoffel_contraction_identity}.
\smallskip

\textbf{Gauss theorem} is immediately proved using Cartan formula and Stokes theorem.
Let $M$ be an oriented manifold with boundary $\partial M$ and $X$ a vector field.
Then
\begin{equation}
    \int_M \mathrm{div}_\Omega (X) = \int_M \mathcal{L}_X \Omega = \int_M d (i_X \Omega) + i_X \graycancel{d\Omega} = \int_{\partial M} i_X \Omega.
\end{equation}
In the case $\Omega$ is the volume form induced by a metric $g$, we can rewrite the right-hand side and get
\begin{equation}
    \int_M \mathrm{div}_g (X) = \int_{\partial M} i_X \Omega_g = \int_{\partial M} g(X, N)\,\, \tilde{\Omega}_g,
\end{equation}
where $N$ is the outward-pointing unit normal vector field on $\partial M$ and $\tilde{\Omega}$ is the volume form induced by the metric on $\partial M$.
It is indeed immediate to check that $i_X \Omega_g = g(X,N) \tilde{\Omega}_g$.

In turn, we have the notion of \textbf{integration by parts}.
First note that for any \emph{arbitrary} volume form
\begin{equation}
    df\wedge i_x \Omega = \left(\partial_\mu f \,dx^\mu\right)\wedge \left(X^{\nu_1} \Omega_{\nu_1 \dots \nu_n} dx^{\nu_2} \wedge \cdots \wedge dx^{\nu_n}\right) = \partial_\mu f X^{\mu}\,\, \Omega = df(X) \,\Omega.
\end{equation}
Then we have 
\begin{equation}
    \int_{\partial M} f\,\, i_X \Omega = \int_M d(f\, i_X \Omega) = \int_M df \wedge i_X \Omega + f\, d i_X\Omega = \int_M df(X) \,\Omega + \int_M f\, \mathrm{div}_\Omega (X).
\end{equation}
In case $\Omega = \sqrt{|g|} dx^1 \wedge \cdots \wedge dx^n$ is the metric volume form this reads
\begin{align}
\begin{aligned}
    \int_{M} f\, \underbrace{\nabla_\mu X^{\mu} \, \Omega_g}_{\mathrm{div}_g(X)}
    &= \int_{\partial M} f\,\, i_X\Omega_g\, - \int_M \underbrace{df(X)}_{= X^{\mu} \partial_\mu f} \, \Omega_g
    = \int_{\partial M} f\,\, g(X,N)\, \tilde{\Omega}_g - \int_M \underbrace{X^{\mu} \partial_\mu f}_{=g(X,\nabla f)}\, \Omega_g,
\end{aligned}
\end{align}
where $\tilde{\Omega}_g$ is the volume form induced by the metric on $\partial M$ and $N$ is the outward-pointing unit normal vector field on $\partial M$.
\end{mytheorem}


\begin{mytheorem}[Curl \& 3D Stokes theorem.]
Given a \emph{Riemannian} manifold $(M,g)$ of dimension $3$ and a vector field $X$, define the 1-from $g(X,\cdot)$, that is lower an index $X_\mu=g_{\mu \nu} X^{\nu}$.
Define the curl as the 2-from obained by taking the exterior derivative
\begin{equation}
    \mathrm{curl} (X) := d (g(X,\cdot)) = d \Big(X_{\mu} \wedge dx^{\mu}\Big).
\end{equation}
Note that in $\mathbb{R}^3$ with the standard Euclidean metric, this definition coincides with the usual notion of curl.
\smallskip

The general Stokes theorem immediately gives the familiar version in $\mathbb{R}^3$:
\begin{equation}
    \int_S \mathrm{curl} (X) =\int_S d (g(X,\cdot)) = \int_{\partial S} g(X,\cdot),
\end{equation}
for any oriented surface $S$ with boundary $\partial S$.
\end{mytheorem}


\begin{mytheorem}[Complex integration \& Gauss-Green Theorem.]
Consider the complex plane as a Riemannian manifold $(\mathbb{R}^2, g)$ with the standard Euclidean metric.
Given a complex homolorphic function $f: \mathbb{C} \to \mathbb{C}$, both the real and imaginary parts \todotag{Finish this}
\end{mytheorem}



%========================================================
\subsection{Hodge dual \& consequences} \todotag{To be written}
%=========================================================

\noindent
\textbf{The Hodge dual.} \todotag{Finish this}
\\
The Hodge dual is \emph{only} defined once we have a pseudoriemannian  metric g on a manifold \(M^{(n)}\). 
Write the induced volume form \(\Omega\) as
\begin{equation}
    \Omega = \Omega_{1\dots n}dx^1 \wedge \cdots \wedge dx^n 
    = \Omega_{\mu_1 \dots \mu_n} dx^{\mu_1} \otimes \cdots \otimes dx^{\mu_n}
    = \frac{1}{n!} \Omega_{\mu_1 \dots \mu_n} dx^{\mu_1} \wedge \cdots \wedge dx^{\mu_n},
\end{equation}
where it is understood that the first expression is \emph{not} summed over indices, while the latter two are and  \(\Omega_{\mu_1 \dots \mu_n}\) is totally antisymmetric.
Then, the Hodge dual of a \(k\)-form \(\alpha\) is the \((n-k)\)-form defined as 
\begin{equation}
    \star \alpha := \frac{1}{k!(n-k)!} \alpha_{\mu_1 \dots \mu_k} \Omega^{\mu_1 \dots \mu_k}_{\quad \quad \nu_{k+1} \dots \nu_n} dx^{\nu_{k+1}} \wedge \cdots \wedge dx^{\nu_n},
\end{equation}
where we raised the indices of \(\Omega\) using the inverse of the volume form, i.e.
\begin{equation}
    \Omega^{\mu_1 \dots \mu_n} := \frac{1}{\Omega_{1\dots n}} \varepsilon^{\mu_1 \dots \mu_n},
\end{equation}
with \(\varepsilon^{\mu_1 \dots \mu_n}\) the Levi-Civita symbol \questiontag{Check signs \& conventions}
\smallskip

One verifies the following important property of the Hodge dual:
\begin{equation}
    \star \star \alpha = (-1)^{k(n-k) + s} \alpha,
\end{equation}
where \(s\) is the signature of the metric \(g\) (i.e. the number of minus signs in the diagonalized form of \(g\)).
\medskip


\noindent
\textbf{The Hodge scalar product on differential forms.} \todotag{Finish this}
\\
Given two \(k\)-forms \(\alpha, \beta\) on a pseudoriemannian manifold \((M,g)\), we define their Hodge product as the scalar product
\begin{equation}
    \langle \alpha, \beta \rangle_{\mathrm{Hodge}} := \int_M \alpha \wedge \star \beta.
\end{equation}
In particular, when \(\alpha = \beta\), we have
\begin{equation}
    \langle \alpha, \alpha \rangle_{\mathrm{Hodge}} = \int_M \alpha \wedge \star \alpha = \int_M ||\alpha||^2 \Omega,
\end{equation}
where \(||\alpha||^2\) is the pointwise norm of \(\alpha\) induced by the metric \(g\).
Note that the signature of this scalar product depends on both the degree \(k\) of the forms and the signature of the metric \(g\).
For example, on the subspace of 1-froms $\Lambda^1 (M)$, the Hodge product has the same signature as the metric \(g\) itself.
\bigskip

\noindent
\textbf{The codifferential.}\todotag{Finish this}
\\
The codifferential \(\delta\) is defined on $k$-forms as
\begin{equation}
    \delta := (-1)^{n(k-1)+1} \star d \star.
\end{equation}
It is an anti-derivative of degree \((0,-1)\) on differential forms i.e. it lowers the degree of a form by one and satisfies the Leibniz rule up to a minus sign.
\smallskip

It obeys the fundamental nilpotency property
\begin{equation}
    \delta^2 = 0,
\end{equation}
just like the exterior derivative \(d\).
\smallskip

Equivalently, the codifferential is defined as (minus) the adjoint of the exterior derivative with respect to the Hodge scalar product, i.e. for any \(k\)-form \(\alpha\) and \((k-1)\)-form \(\beta\), we have
\begin{equation}
    \langle d \beta, \alpha \rangle_{\mathrm{Hodge}} = \langle \beta, -\delta \alpha \rangle_{\mathrm{Hodge}}.
\end{equation}
\medskip
The minus sign is a convention to accomodate the expression below for the Laplace-de Rham operator.
\bigskip

\noindent
\textbf{Laplace-de Rham-D'Alambert operator.}\todotag{Finish this}
\\
The Laplace-de Rham-D'Alambert operator \(\Delta\) is defined on differential forms as
\begin{equation}
    \Delta := d \delta + \delta d.
\end{equation}
It is a derivative of degree \((0,0)\) on differential forms i.e. it preserves the degree of a form and satisfies the usual Leibniz rule.
\smallskip

Depending on the signature of the pseudoriemannian metric \(g\), it generalizes either the Laplacian (Riemannian case) or the D'Alambert operator (Lorentzian case) or anything in between (general pseudoriemannian case). 
In the Lorentzian case it is often denote by \(\Box\).
In the Riemannian case, it is positive semidefinite.
In the Lorentzian case, it is hyperbolic.
This can be easily seen in flat Riemannian or Minkowski space, passing to Fourier space.
\begin{equation}
    p_E^2 = p_1^2 + p_2^2 + p_3^2 + \cdots \geq 0,\quad p_M^2 = p_0^2 - p_1^2 - p_2^2 - \cdots.
\end{equation}

It satisfies the following properties:
\begin{itemize}
    \item $d \,\Box = \Box\, d$,
    \item $\delta \,\Box = \Box\, \delta$,
    \item $\Box$ is self-adjoint with respect to the Hodge scalar product.
\end{itemize}
\medskip

In cohordinate form, on a \(k\)-form \(\alpha\), it reads
\begin{equation}
    (\Delta \alpha)_{\mu_1 \dots \mu_k} = - \nabla^{\nu} \nabla_{\nu} \alpha_{\mu_1 \dots \mu_k} + \sum_{i=1}^k (-1)^i R^{\nu}_{\quad \mu_i} \alpha_{\nu \mu_1 \dots \hat{\mu}_i \dots \mu_k} - 2 \sum_{1 \leq < p \le k} (-1)^{p+q} R^{\nu}_{\quad \mu_i \mu_j \mu_p} \alpha_{\nu \mu_1 \dots \hat{\mu}_i \dots \hat{\mu}_j \dots \mu_k},
\end{equation}
where hats denote omitted indices and \(R^{\rho}_{\quad \sigma \mu \nu}\) is the Riemann curvature tensor.
In particular, on functions (0-forms) it reduces to the usual Laplacian/D'Alambert operator
\begin{equation}
    \Delta f = - \nabla^{\nu} \nabla_{\nu} f.
\end{equation}
\medskip

The Laplace-D'Alambert operator can equivalently be understood as the square of the Dirac operator acting on differential forms, defined as
\begin{equation}
    \slashed{D} := d + \delta.
\end{equation}
Indeed, one has
\begin{equation}
    \slashed{D}^2 = (d + \delta)^2 = d^2 + d \delta + \delta d + \delta^2 = d \delta + \delta d = \Delta,
\end{equation}
where we used the nilpotency of both \(d\) and \(\delta\).
\medskip

Alternatively, the Laplace-D'Alambert operator can equivalently be defined as the unique derivative of degree \((0,0)\) on differential forms that reduces to the usual Laplacian/D'Alambert operator on functions and commutes with both \(d\) and \(\delta\).

Finally, its action on 0-forms can be understood as the operator featuring in the Euler-Lagrange equations for the action functional
\begin{equation}
    S[\phi] = \frac{1}{2} \int_M d\phi \wedge \star d\phi = \frac{1}{2} \int_M ||d\phi||^2 \Omega = \frac{1}{2}\int_M \sqrt{|g|}\,\partial_\mu \phi \partial^\mu \phi\, d^n x,
\end{equation}
where \(\phi\) is a scalar field (0-form).
Varying with respect to \(\phi\), one finds
\begin{equation}
    \delta S[\phi] = \int_M \delta \phi \, \star \Delta \phi,
\end{equation}
so that the Euler-Lagrange equations read
\begin{equation}
    \Delta \phi = 0.
\end{equation}


%========================================================
\subsection{Closed vs exact forms \& de Rham cohomology} \todotag{To be written}
%=========================================================


\begin{mytheorem}[Closed \& exact forms]
A differential form \(\omega \in \Lambda^k (M)\) is called \textbf{closed} if \(d\omega = 0\).
It is called \textbf{exact} if there exists a \((k-1)\)-form \(\alpha\) such that \(\omega = d\alpha\).
Because \(d^2 = 0\), every exact form is closed.
The converse is not true in general, as we will see when discussing de Rham cohomology.
\end{mytheorem}


\begin{theorem}[PoincarÃ© lemma]
Let \(M\) be a smooth manifold and let \(U \subseteq M\) be a contractible open subset.
Then, every closed differential form \(\omega \in \Lambda^k (U)\) is exact, i.e. there exists a \((k-1)\)-form \(\alpha\) such that \(\omega = d\alpha\).
This theorem has extensions to more general \emph{homotopically trivial} subsets.
\end{theorem}


%-----------------------------------------------------------------------
%======================================================================
\section{Torsion \& equivalence principle}\todotag{To be written}
%========================================================================
%-------------------------------------------------------------------------


\begin{mytheorem}[Torsion measure the nonclosure of parallelograms]
Consider a manifold \(M\) with an affine connection \(\nabla\).
Let \(X,Y\) be two vector fields on \(M\).
Construct the parallelogram starting from a point \(p \in M\) by first following the flow of \(X\) for a parameter distance \(\epsilon\), then the flow of \(Y\) for a parameter distance \(\epsilon\), then the flow of \(-X\) for a parameter distance \(\epsilon\), and finally the flow of \(-Y\) for a parameter distance \(\epsilon\).
Then, the endpoint of this parallelogram differs from the starting point \(p\) by a vector given, at leading order in \(\epsilon\), by
\begin{equation}
    \Delta p = \epsilon^2 T(X,Y) + \mathcal{O}(\epsilon^3),
\end{equation}
where \(T(X,Y)\) is the torsion tensor evaluated on \(X\) and \(Y\).
\end{mytheorem}


\begin{mytheorem}[Why torsion is a tensor?]
The fact that torsion is a tensor, even though the Christoffel symbols are not, follows directly from its geometric definition as measuring the nonclosure of parallelograms.
Alternatively, we could view it from the `physicitsts definition of tensors' and its antisymmetric nature.
Under a change of frame the Christoffel symbols transform as
\begin{equation}
    \Gamma^{\rho}_{\mu \nu} = \frac{\partial x^{\rho}}{\partial x^{\prime \sigma}} \frac{\partial x^{\prime \alpha}}{\partial x^{\mu}} \frac{\partial x^{\prime \beta}}{\partial x^{\nu}} \Gamma^{\prime \sigma}_{\alpha \beta} + \frac{\partial x^{\rho}}{\partial x^{\prime \sigma}} \frac{\partial^2 x^{\prime \sigma}}{\partial x^{\mu} \partial x^{\nu}}.
\end{equation}
The nontensorial part of the transformation is symmetric in the lower indices \(\mu, \nu\).
Therefore by splitting
\begin{equation}
    \Gamma^{\rho}_{\mu \nu} = \Gamma^{\rho}_{(\mu \nu)} + \Gamma^{\rho}_{[\mu \nu]},
\end{equation}
we see that indeed $T_{\mu,\nu}^{\quad \rho} = 2 \Gamma^{\rho}_{[\mu \nu]}$ transforms as a tensor.
\end{mytheorem}


\begin{mytheorem}[Torsion \& the equivalence principle]
The equivalence principle demands torsion to vanish.
Indeed, if we require that at any point there exists a local freely falling frame where the connection coefficients vanish, then the torsion must vanish as well.
Since torsion is a tensor, if it vanishes in one cohordinate system, it must vanish in all.
In fact, the vanishing ot torsion not only is needed, but is equivalent to the existence of such local freely falling frames as we next show.
\end{mytheorem}


\begin{theorem}
Let \(M\) be a manifold with an affine connection \(\nabla\).
Then, the torsion of \(\nabla\) vanishes if and only if for any point \(p \in M\) there exists a local coordinate system \(\{x^{\mu}\}\) around \(p\) such that the connection coefficients vanish at \(p\), i.e. \(\Gamma^{\rho}_{\mu \nu} (p) = 0\).
\end{theorem}
\begin{proof}
Very simple exercise.
\end{proof}


\begin{mytheorem}[Quantum gravity \& allowing for nonzero torsion]
If we want to quantize gravity, it is wise and natural to allow for some nonzero torsion.
Indeed, in quantum mechanics all quantities are subject to quantum fluctuations.
Therefore, if the metric is quantum fluctuating, it might well be the case that it explores also configurations with nonzero torsion.

Indeed, we have several examples where quantum fuctuations violate classical constraints.
An example is quantum tunnelling, particles can cross classically forbidden regions.

Another one is the nonvanishing of correlators between spacelike separated operators in quantum field theory, violating classical causality.
In this second case, the `rules' of classical general relativity are restored by the fact that these acausal correlators are exponentially suppressed at scales larger than the Compton wavelength of the particles involved.
Furthermore, the analogous contributions from particles and antiparticles cancel each other in the actually observable correlator.
\end{mytheorem}


\begin{mytheorem}[The Levi-Civita metric connection.]
Given a pseudoriemannian manifold \((M,g)\), there exists a unique connection \(\nabla\) that is both torsion-free and metric-compatible, i.e. 
\begin{equation}
    \nabla g = 0, \quad T_\nabla = 0.
\end{equation}
The Christoffel symbols are uniquely determined by the metric as
\begin{equation}\label{eq:levi_civita_christoffel_symbols}
    \Gamma^{\rho}_{\mu \nu} = \frac{1}{2} g^{\rho \sigma} \left( \partial_{\mu} g_{\nu \sigma} + \partial_{\nu} g_{\mu \sigma} - \partial_{\sigma} g_{\mu \nu} \right).
\end{equation}
%
The \textbf{contraction of the Christoffel symbols} of the Levi-Civita connection satisfy the identity
\begin{equation}\label{eq:metric_christoffel_contraction_identity}
    \Gamma^{\mu}_{\mu \nu} = \frac{1}{\sqrt{|g|}} \partial_{\nu} \sqrt{|g|}.
\end{equation}   
\end{mytheorem}
\begin{proof}
From the Levi-Civita formula \eqref{eq:levi_civita_christoffel_symbols} we have
\begin{equation}
    \Gamma^{\mu}_{\mu \nu} = \frac{1}{2} g^{\mu \sigma} \left( \partial_{\mu} g_{\nu \sigma} + \partial_{\nu} g_{\mu \sigma} - \partial_{\sigma} g_{\mu \nu} \right) = \frac{1}{2} g^{\mu \sigma} \partial_{\nu} g_{\mu \sigma},
\end{equation}
where two terms cancel due to the symmetry of \(g_{\mu \nu}\).
Differentiating the determinant of the metric, 
\begin{align}
\begin{aligned}
    \partial_{\nu} \sqrt{|g|} &= \frac{1}{2 \sqrt{|g|}} \text{sign}(g) \det(g_{\mu \nu}) \, \text{Tr}\big(g^{\alpha \beta} \partial_{\nu} g_{\beta \gamma}\big)
    = \frac{1}{2} \sqrt{|g|}\,\, g^{\alpha \beta} \partial_{\nu} g_{\beta \alpha}
    = \sqrt{|g|} \,\,\Gamma^{\mu}_{\mu \nu}.
\end{aligned}
\end{align}
\end{proof}


%-----------------------------------------------------------------------
%======================================================================
\section{Curvature}\todotag{To be written}
%========================================================================
%---------------------------------------------------------------------------

What is curvature? How do we even measure it? Intuitively, curvature is how much a space deviates from being flat.
Here are some ways to quantify this. 
\begin{enumerate}
\item \textbf{Violation of angle sum laws.}  For a triangle with angles \(\alpha,\beta,\gamma\) one has
\[
\alpha + \beta + \gamma \neq 180^\circ.
\]
Such a \emph{deficit angle} can be used to encode the shape.  (This idea is used in some approaches to quantum gravity.)
\item \textbf{Violation of Pythagoras' law.}  For a triangle with side lengths \(a,b,c\) one has
\[
a^2 + b^2 \neq c^2.
\]
Thus one can encode the shape through metric distances, i.e. via a Riemannian metric \(g\) on \(M\).
\item \textbf{Nontrivial parallel transport around loops.}  A vector transported around a closed loop generally does not return to itself.  One can therefore encode the shape through an affine connection \(\Gamma\) on \(M\).
\end{enumerate}

\begin{mytheorem}[Measuring distances \& curvature with Green functions]
The n-point correlators do know about the geometry of the underlying manifold.
Indeed, the 2-point correlator (Green function) of a free scalar field theory on a curved manifold \((M,g)\) satisfies
\begin{equation}
    (\Box_x + m^2) G(x,y) = - \frac{1}{\sqrt{|g|}} \delta^{(n)} (x-y),
\end{equation}
where \(\Box\) is the D'Alambert operator associated to the metric \(g\).
From the knowledge of the Green function \(G(x,y)\) for all pairs of points \((x,y) \in M \times M\), one can reconstruct the metric \(g\) and therefore the curvature of the manifold.    
\end{mytheorem}


%=======================================================
\subsection{The Riemann curvature tensor}
%=======================================================

The Riemann curvature tensor is defined as the operator measuring the noncommutativity of covariant derivatives.

\begin{mytheorem}[The Riemann tensor measures the noncommutativity of parallel transport in two directions]
If we neglect torsion the path obtained by first following the flow of a vector field \(X\) for infinitesimal distance \(\epsilon\), then the flow of a vector field \(Y\) for infinitesimal distance \(\epsilon\), then the flow of \(-X\) for infinitesimal distance \(\epsilon\), and finally the flow of \(-Y\) for infinitesimal distance \(\epsilon\), closes to leading order in \(\epsilon\).
In presence of torsion, the parallelogram does not close, but the Riemann tensor retains its meaning as measuring the noncommutativity of covariant derivatives.
\end{mytheorem}

\begin{mytheorem}[The Riemann tensor is just a rotation matrix in disguise]
     Indeed...

\end{mytheorem}



%-----------------------------------------------------------
%=======================================================
\section{Tetrad formalism \& tensor-valued forms}\todotag{To be written}
%=======================================================
%------------------------------------------------------------

The tetrad formalism amount to allowing arbitrary frames for the tangent $\{e_i(x)\}_i$ and cotangent  $\{\theta^i(x)\}_i$ bundles, not necessarily induced by a coordinate system.
The only typical requirement is that the two frame are dual to each other, i.e. $\theta^i (e_j) = \delta^i_j$.
In the literature, tetrads are also called \emph{vierbeins} (4-legs) in 4 dimensions or more generally \emph{vielbeins} (n-legs) in n dimensions.


\begin{mytheorem}[Avantages \& disadvantages of the tetrad formalism]
The main advantage of the tetrad formalism is that coefficients of tensors in arbitrary frames transform as scalars under coordinate transformations.
That is, their coordinates with respect to the tetrad bases do not change under change of coordinates, simply because we change the cohordinates $x^\mu\to \tilde{x}^\mu$ but the tetrad bases $\{e_i(x)\}_i$, $\{\theta^i(x)\}_i$ remain the same.
The main disadvantage is that expressions might get longer or more cumbersome, since we cannot use the simplifications coming from coordinate bases e.g. the fact that $d (dx^\mu) = 0$ or $[\partial_\mu, \partial_\nu] = 0$.

In any case, this has several advtanges.
For example, we can choose a tetrad that is orthonormal with respect to a given metric $g$ i.e.
\begin{equation}
    g = \eta_{ij} \theta^i \otimes \theta^j,
\end{equation}
where $\eta_{ij}=\text{diag}(\pm1\dots \pm1)$ is the Minkowski (or Euclidean) metric.
This is particularly useful for spinors.
By definition, in any chosen frame, the $\gamma$ matrices are required to respect the Clifford algebra
\begin{equation}
    \{\gamma^\mu, \gamma^\nu\} = 2 g_{\mu\nu} \mathbb{I}.
\end{equation}
In the such a orthonormal frame, this reduces to $\{\gamma^\mu, \gamma^\nu\} = 2 \eta_{\mu\nu} \mathbb{I}$ and we can take the $\gamma^\mu$ as in the usual Clifford algebra in flat space all over the manifold.
\end{mytheorem}


\begin{mytheorem}[Fiber valued differential forms]
Fiber valued differential forms are just usual $p$-forms taking values in a fiber space $F$.
That is, given a fibre bundle $E_F\to M$ with fibre $F$, a fiber valued $p$-form is a section of the product bundle
\begin{equation}
    \Lambda^p (M) \otimes E_F \to M.
\end{equation}
For example when $E_F = T^h_kM$ is the bundle of $(h,k)$-tensors we have tensor-valued differential forms.
This notion generalizes all the structures we have seen so far.
\begin{itemize}
    \item A usual differential $p$-form is just a fiber valued $p$-form with trivial fiber $F = \mathbb{R}$.
    \item An $(h,k)$-tensor field is just a fiber valued $0$-form with fiber $F = T^h_k M$.
\end{itemize}

In fact, since $\Lambda*(M)\subset T^*_*(M)$ the splitting in `differntial form part' and `tensor valued image' is somewhat arbitrary.
The most natural convention is to take all the antisymmetric part as the differential form part and the rest as the tensor valued image.
For example
\begin{itemize}
    \item The torsion $T_{\mu\nu}^{\quad \rho}$, antisymmetric in the $\mu\nu$ indices, is a $(1,0)$-tensor valued 2-form, i.e. a fiber valued 2-form with fiber $F = T^1_0 M$.
    \item The Riemann curvature $R_{\rho, \mu \nu}^{\quad \sigma}$, antisymmetric in the $\mu\nu$ indices, is a $(1,1)$-tensor valued 2-form, i.e. a fiber valued 2-form with fiber $F = T^1_1 M$.
\end{itemize}
\end{mytheorem}


\begin{mytheorem}[Exterior covariant derivative]
Given a fiber bundle $E_F \to M$ with fiber $F$ and an affine connection $\nabla$ on $M$, we can define the exterior covariant derivative $D$ acting on fiber valued $p$-forms as the unique map
\begin{equation}
    D: \Lambda^p (M) \otimes E_F \to \Lambda^{p+1} (M) \otimes E_F
\end{equation}
that is linear, satisfies the Leibniz rule
\begin{equation}
    D(\alpha \wedge \beta) = (D\alpha) \wedge \beta + (-1)^p \alpha \wedge (D\beta),
\end{equation}
for any fiber valued $p$-form $\alpha$ and fiber valued $q$-form $\beta$, and reduces to the usual covariant derivative $\nabla$ when acting on fiber valued $0$-forms.
\end{mytheorem}


%===============================================================================
\subsection{Curvature forms \& Cartan structure equations}\todotag{To be written}
%================================================================================


\begin{mytheorem}[Structure constants of a tetrad frame]
Given a frame $\{\theta^i\}_i$ for the cotangent bundle, we can define its structure constants $C^i_{\quad jk}$ as the coefficients in the expansion
\begin{equation}
    d \theta^i = - \frac{1}{2} C^i_{\quad jk} \theta^j \wedge \theta^k.
\end{equation}
These structure constants measure the nonclosure of infinitesimal parallelograms constructed using the tetrad basis vector fields $\{e_i\}_i$ dual to $\{\theta^i\}_i$.
Indeed, one can show that
\begin{equation}
    [e_j, e_k] = C^i_{\quad jk} e_i.
\end{equation}
If the tetrad is induced by a coordinate system, then the structure constants vanish identically.
\end{mytheorem}


\begin{mytheorem}[Connection 1-forms]
Given an affine connection $\nabla$ on a manifold $M$ and a tetrad frame $\{\theta^i\}_i$, we can define the connection 1-forms $\omega^i_{~j}$ as the set of 1-forms satisfying
\begin{equation}
    \nabla e_j = \omega^i_{~ j} \otimes e_i.
\end{equation}
In particular, the covariant derivative of a vector field $X = X^i e_i$ reads
\begin{equation}
    \nabla X = (dX^i + \omega^i_{~ j}\,\, X^j) \otimes e_i.
\end{equation}
Under a change of tetrad frame $\{\theta^i\}_i \to \{\tilde{\theta}^i = A^i_{\quad j} \theta^j\}_i$, the connection 1-forms transform as
\begin{equation}
    \tilde{\omega}^i_{~ j} = (A^{-1})^i_{\quad k} \omega^k_{~ l} A^l_{\quad j} + (A^{-1})^i_{\quad k} d A^k_{\quad j}.
\end{equation}
\end{mytheorem}


\begin{mytheorem}[Curvature 2-forms]
Given an affine connection $\nabla$ on a manifold $M$ and a tetrad frame $\{\theta^i\}_i$, we can define the curvature 2-forms $\Omega^i_{j}$ as the set of 2-forms satisfying
\begin{equation}
    R(e_j) = \Omega^i_{j} \otimes e_i\,,
\end{equation}
where $R$ is the Riemann curvature operator.
In particular, the Riemann curvature operator acting on a vector field $X = X^i e_i$ reads
\begin{equation}
    R(X) =  X^j\,\, \Omega^i_{~j}\otimes e_i.
\end{equation}
\end{mytheorem}


\begin{mytheorem}[Cartan structure equations]
The torsion and curvature 2-forms satisfy the Cartan structure equations
\begin{align}
    T^i &= d \theta^i + \omega^i_{~ j} \wedge \theta^j,
    \\
    \Omega^i_{~ j} &= d \omega^i_{~ j} + \omega^i_{~ k} \wedge \omega^k_{~ j}.
\end{align}
In particular, in absence of torsion the first Cartan structure equation reduces to
\begin{equation}
    d \theta^i + \omega^i_{~ j} \wedge \theta^j = 0.
\end{equation}
\end{mytheorem}